{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07516430-3601-4d08-8397-c5013f3df13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No headline data found. Using sample data for demonstration.\n",
      "Loaded 100 headlines\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>Kenya's economy grows 5.2% in Q1</td>\n",
       "      <td>general</td>\n",
       "      <td>sample_data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>NSE 20-share index gains 3% amid positive inve...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>sample_data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-03</td>\n",
       "      <td>Central Bank of Kenya maintains base rate at 9.5%</td>\n",
       "      <td>economy</td>\n",
       "      <td>sample_data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-04</td>\n",
       "      <td>Safaricom reports 10% profit increase in annua...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>sample_data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-05</td>\n",
       "      <td>Equity Bank expands into South Sudan market</td>\n",
       "      <td>banking</td>\n",
       "      <td>sample_data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                           headline category  \\\n",
       "0 2025-01-01                   Kenya's economy grows 5.2% in Q1  general   \n",
       "1 2025-01-02  NSE 20-share index gains 3% amid positive inve...   stocks   \n",
       "2 2025-01-03  Central Bank of Kenya maintains base rate at 9.5%  economy   \n",
       "3 2025-01-04  Safaricom reports 10% profit increase in annua...   stocks   \n",
       "4 2025-01-05        Equity Bank expands into South Sudan market  banking   \n",
       "\n",
       "        source  \n",
       "0  sample_data  \n",
       "1  sample_data  \n",
       "2  sample_data  \n",
       "3  sample_data  \n",
       "4  sample_data  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# NLP Libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Visualization styling\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Define paths\n",
    "news_data_dir = \"../data/external/news_data/\"\n",
    "kenya_finance_dir = os.path.join(news_data_dir, \"kenya_finance_data\")\n",
    "international_finance_dir = os.path.join(news_data_dir, \"international_finance_data\")\n",
    "crypto_finance_dir = os.path.join(news_data_dir, \"crypto_finance_data\")\n",
    "forex_finance_dir = os.path.join(news_data_dir, \"forex_finance_data\")\n",
    "output_dir = \"../outputs/sentiment_analysis\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to load and combine headline data from different sources\n",
    "def load_news_headlines():\n",
    "    headline_files = [\n",
    "        os.path.join(kenya_finance_dir, \"financial_news_headlines.csv\"),\n",
    "        # Add other headline files if they exist\n",
    "    ]\n",
    "    \n",
    "    all_headlines = []\n",
    "    \n",
    "    for file_path in headline_files:\n",
    "        if os.path.exists(file_path):\n",
    "            print(f\"Loading headlines from {file_path}\")\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                # Add source column to track origin\n",
    "                df['source'] = os.path.basename(file_path).replace('.csv', '')\n",
    "                all_headlines.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file_path}: {e}\")\n",
    "    \n",
    "    if all_headlines:\n",
    "        combined_headlines = pd.concat(all_headlines, ignore_index=True)\n",
    "        return combined_headlines\n",
    "    else:\n",
    "        print(\"No headline data found. Using sample data for demonstration.\")\n",
    "        # Create sample data\n",
    "        sample_data = {\n",
    "            'date': pd.date_range(start='2025-01-01', periods=100),\n",
    "            'headline': [\n",
    "                \"Kenya's economy grows 5.2% in Q1\",\n",
    "                \"NSE 20-share index gains 3% amid positive investor sentiment\",\n",
    "                \"Central Bank of Kenya maintains base rate at 9.5%\",\n",
    "                \"Safaricom reports 10% profit increase in annual results\",\n",
    "                \"Equity Bank expands into South Sudan market\",\n",
    "                \"KCB Group completes acquisition of DRC bank\",\n",
    "                \"Rising inflation concerns impact Kenyan shilling\",\n",
    "                \"NSE records worst day in 2 years as global markets tumble\",\n",
    "                \"Kenya's debt burden increase raises economic concerns\",\n",
    "                \"Crypto adoption surges in East Africa despite regulatory concerns\"\n",
    "            ] * 10,\n",
    "            'category': ['general', 'stocks', 'economy', 'stocks', 'banking', \n",
    "                        'banking', 'forex', 'stocks', 'economy', 'crypto'] * 10,\n",
    "            'source': ['sample_data'] * 100\n",
    "        }\n",
    "        return pd.DataFrame(sample_data)\n",
    "\n",
    "# Load headline data\n",
    "headlines_df = load_news_headlines()\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Loaded {len(headlines_df)} headlines\")\n",
    "headlines_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94b9c29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per column:\n",
      "date        0\n",
      "headline    0\n",
      "category    0\n",
      "source      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>processed_headline</th>\n",
       "      <th>enhanced_headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kenya's economy grows 5.2% in Q1</td>\n",
       "      <td>kenya economy grows q</td>\n",
       "      <td>kenya economy grows q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NSE 20-share index gains 3% amid positive inve...</td>\n",
       "      <td>nse share index gain amid positive investor se...</td>\n",
       "      <td>nse share index gain amid positive investor se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Central Bank of Kenya maintains base rate at 9.5%</td>\n",
       "      <td>central bank kenya maintains base rate</td>\n",
       "      <td>central bank kenya maintains base rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Safaricom reports 10% profit increase in annua...</td>\n",
       "      <td>safaricom report profit increase annual result</td>\n",
       "      <td>safaricom profit increase annual result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Equity Bank expands into South Sudan market</td>\n",
       "      <td>equity bank expands south sudan market</td>\n",
       "      <td>equity bank expands south sudan market</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0                   Kenya's economy grows 5.2% in Q1   \n",
       "1  NSE 20-share index gains 3% amid positive inve...   \n",
       "2  Central Bank of Kenya maintains base rate at 9.5%   \n",
       "3  Safaricom reports 10% profit increase in annua...   \n",
       "4        Equity Bank expands into South Sudan market   \n",
       "\n",
       "                                  processed_headline  \\\n",
       "0                              kenya economy grows q   \n",
       "1  nse share index gain amid positive investor se...   \n",
       "2             central bank kenya maintains base rate   \n",
       "3     safaricom report profit increase annual result   \n",
       "4             equity bank expands south sudan market   \n",
       "\n",
       "                                   enhanced_headline  \n",
       "0                              kenya economy grows q  \n",
       "1  nse share index gain amid positive investor se...  \n",
       "2             central bank kenya maintains base rate  \n",
       "3            safaricom profit increase annual result  \n",
       "4             equity bank expands south sudan market  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert date column to datetime\n",
    "if 'date' in headlines_df.columns:\n",
    "    headlines_df['date'] = pd.to_datetime(headlines_df['date'], errors='coerce')\n",
    "    # Filter out rows with invalid dates\n",
    "    headlines_df = headlines_df[~headlines_df['date'].isna()]\n",
    "    # Sort by date\n",
    "    headlines_df = headlines_df.sort_values('date')\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(headlines_df.isna().sum())\n",
    "\n",
    "# Fill missing values in category if any\n",
    "if 'category' in headlines_df.columns and headlines_df['category'].isna().any():\n",
    "    headlines_df['category'] = headlines_df['category'].fillna('general')\n",
    "\n",
    "# Function to clean and preprocess text\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Preprocess headlines\n",
    "headlines_df['clean_headline'] = headlines_df['headline'].apply(preprocess_text)\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def tokenize_and_lemmatize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "headlines_df['tokens'] = headlines_df['clean_headline'].apply(tokenize_and_lemmatize)\n",
    "headlines_df['processed_headline'] = headlines_df['tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Add financial domain specific words to be filtered out or kept\n",
    "financial_specific_stopwords = [\n",
    "    'said', 'says', 'report', 'reported', 'according', \n",
    "    'announces', 'announced', 'statement', 'press', 'release'\n",
    "]\n",
    "\n",
    "# Enhanced preprocessing specifically for financial headlines\n",
    "def enhance_financial_preprocessing(tokens):\n",
    "    enhanced_tokens = [token for token in tokens if token not in financial_specific_stopwords]\n",
    "    return enhanced_tokens\n",
    "\n",
    "headlines_df['enhanced_tokens'] = headlines_df['tokens'].apply(enhance_financial_preprocessing)\n",
    "headlines_df['enhanced_headline'] = headlines_df['enhanced_tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Display processed headlines\n",
    "headlines_df[['headline', 'processed_headline', 'enhanced_headline']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16894071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment Distribution (VADER):\n",
      "sentiment\n",
      "neutral     0.5\n",
      "positive    0.3\n",
      "negative    0.2\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Sentiment Distribution (Loughran-McDonald):\n",
      "lm_sentiment_label\n",
      "neutral     0.4\n",
      "positive    0.3\n",
      "negative    0.3\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Initialize VADER sentiment analyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to get VADER sentiment scores\n",
    "def get_vader_sentiment(text):\n",
    "    if not isinstance(text, str) or text == \"\":\n",
    "        return {\n",
    "            'compound': 0,\n",
    "            'pos': 0,\n",
    "            'neu': 0,\n",
    "            'neg': 0\n",
    "        }\n",
    "    return sid.polarity_scores(text)\n",
    "\n",
    "# Apply VADER to original headlines (better for short texts like headlines)\n",
    "headlines_df['vader_scores'] = headlines_df['headline'].apply(get_vader_sentiment)\n",
    "\n",
    "# Extract individual sentiment scores\n",
    "headlines_df['vader_compound'] = headlines_df['vader_scores'].apply(lambda x: x['compound'])\n",
    "headlines_df['vader_positive'] = headlines_df['vader_scores'].apply(lambda x: x['pos'])\n",
    "headlines_df['vader_neutral'] = headlines_df['vader_scores'].apply(lambda x: x['neu'])\n",
    "headlines_df['vader_negative'] = headlines_df['vader_scores'].apply(lambda x: x['neg'])\n",
    "\n",
    "# Create a simple sentiment label\n",
    "def get_sentiment_label(compound_score):\n",
    "    if compound_score >= 0.05:\n",
    "        return 'positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "headlines_df['sentiment'] = headlines_df['vader_compound'].apply(get_sentiment_label)\n",
    "\n",
    "# ### 3.2 Financial-Specific Lexicon (Loughran-McDonald)\n",
    "\n",
    "# Load the Loughran-McDonald financial sentiment dictionary\n",
    "# Note: In a real implementation, you would download and incorporate this lexicon\n",
    "# For demonstration purposes, we'll create a simplified version\n",
    "\n",
    "lm_positive = [\n",
    "    'up', 'upward', 'climb', 'gain', 'increase', 'grow', 'growth', 'improved', 'rises', 'rising',\n",
    "    'positive', 'profit', 'profitable', 'success', 'successful', 'good', 'strong', 'stronger',\n",
    "    'highest', 'record', 'opportunity', 'opportunities', 'outperform', 'exceeded', 'beat',\n",
    "    'dividend', 'upgrade', 'recommended', 'buy', 'advantage', 'optimistic', 'optimism'\n",
    "]\n",
    "\n",
    "lm_negative = [\n",
    "    'down', 'downward', 'fall', 'fell', 'decline', 'drop', 'decrease', 'shrink', 'shrinking',\n",
    "    'negative', 'loss', 'losses', 'fail', 'failed', 'weak', 'weaker', 'lowest', 'poor',\n",
    "    'underperform', 'miss', 'missed', 'disappointing', 'disappointed', 'warning', 'risk',\n",
    "    'risks', 'risky', 'concern', 'concerns', 'sell', 'downgrade', 'cautious', 'caution', 'recession',\n",
    "    'debt', 'inflation', 'deficit', 'crisis', 'problem', 'lawsuit', 'litigation', 'scandal'\n",
    "]\n",
    "\n",
    "# Function to calculate Loughran-McDonald sentiment\n",
    "def get_lm_sentiment(tokens):\n",
    "    if not tokens:\n",
    "        return {'positive': 0, 'negative': 0, 'net': 0}\n",
    "    \n",
    "    positive_count = sum(1 for token in tokens if token in lm_positive)\n",
    "    negative_count = sum(1 for token in tokens if token in lm_negative)\n",
    "    \n",
    "    total_count = len(tokens)\n",
    "    if total_count == 0:\n",
    "        return {'positive': 0, 'negative': 0, 'net': 0}\n",
    "    \n",
    "    positive_score = positive_count / total_count\n",
    "    negative_score = negative_count / total_count\n",
    "    net_score = positive_score - negative_score\n",
    "    \n",
    "    return {\n",
    "        'positive': positive_score,\n",
    "        'negative': negative_score,\n",
    "        'net': net_score\n",
    "    }\n",
    "\n",
    "# Apply Loughran-McDonald sentiment analysis\n",
    "headlines_df['lm_sentiment'] = headlines_df['tokens'].apply(get_lm_sentiment)\n",
    "headlines_df['lm_positive'] = headlines_df['lm_sentiment'].apply(lambda x: x['positive'])\n",
    "headlines_df['lm_negative'] = headlines_df['lm_sentiment'].apply(lambda x: x['negative'])\n",
    "headlines_df['lm_net'] = headlines_df['lm_sentiment'].apply(lambda x: x['net'])\n",
    "\n",
    "# Create a simple LM sentiment label\n",
    "def get_lm_sentiment_label(net_score):\n",
    "    if net_score > 0.05:\n",
    "        return 'positive'\n",
    "    elif net_score < -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "headlines_df['lm_sentiment_label'] = headlines_df['lm_net'].apply(get_lm_sentiment_label)\n",
    "\n",
    "# Compare VADER and Loughran-McDonald sentiment\n",
    "print(\"\\nSentiment Distribution (VADER):\")\n",
    "print(headlines_df['sentiment'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nSentiment Distribution (Loughran-McDonald):\")\n",
    "print(headlines_df['lm_sentiment_label'].value_counts(normalize=True))\n",
    "\n",
    "# Visualize agreement between the two approaches\n",
    "plt.figure(figsize=(10, 6))\n",
    "agreement_df = pd.crosstab(headlines_df['sentiment'], headlines_df['lm_sentiment_label'], normalize='index')\n",
    "sns.heatmap(agreement_df, annot=True, cmap='Blues', fmt='.2f')\n",
    "plt.title('Agreement Between VADER and Loughran-McDonald Sentiment')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'sentiment_agreement.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab1d4a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Accuracy: 1.000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00         2\n",
      "     neutral       1.00      1.00      1.00        11\n",
      "    positive       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare features using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, min_df=5, max_df=0.7)\n",
    "X = tfidf_vectorizer.fit_transform(headlines_df['processed_headline'])\n",
    "y = headlines_df['sentiment']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a logistic regression model\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = lr_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nLogistic Regression Accuracy: {accuracy:.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Create a confusion matrix visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['negative', 'neutral', 'positive'],\n",
    "            yticklabels=['negative', 'neutral', 'positive'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'confusion_matrix.png'))\n",
    "plt.close()\n",
    "\n",
    "# ## 4. Sentiment Aggregation and Trends\n",
    "\n",
    "# Group by date and calculate daily sentiment\n",
    "if 'date' in headlines_df.columns:\n",
    "    # Ensure we have a date column and it's in datetime format\n",
    "    daily_sentiment = headlines_df.groupby(headlines_df['date'].dt.date).agg({\n",
    "        'vader_compound': 'mean',\n",
    "        'lm_net': 'mean',\n",
    "        'headline': 'count'\n",
    "    }).reset_index()\n",
    "    \n",
    "    daily_sentiment.rename(columns={'headline': 'headline_count'}, inplace=True)\n",
    "    \n",
    "    # Calculate rolling averages (7-day window)\n",
    "    daily_sentiment['vader_7d_rolling'] = daily_sentiment['vader_compound'].rolling(7).mean()\n",
    "    daily_sentiment['lm_7d_rolling'] = daily_sentiment['lm_net'].rolling(7).mean()\n",
    "    \n",
    "    # Plot daily sentiment trends\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(daily_sentiment['date'], daily_sentiment['vader_compound'], 'b-', alpha=0.3, label='Daily VADER')\n",
    "    plt.plot(daily_sentiment['date'], daily_sentiment['vader_7d_rolling'], 'b-', linewidth=2, label='7-day VADER Rolling Avg')\n",
    "    plt.plot(daily_sentiment['date'], daily_sentiment['lm_net'], 'r-', alpha=0.3, label='Daily LM')\n",
    "    plt.plot(daily_sentiment['date'], daily_sentiment['lm_7d_rolling'], 'r-', linewidth=2, label='7-day LM Rolling Avg')\n",
    "    plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    plt.title('Financial News Headlines Sentiment Trend')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Sentiment Score')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'sentiment_trend.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Analyze sentiment by news category\n",
    "if 'category' in headlines_df.columns:\n",
    "    category_sentiment = headlines_df.groupby('category').agg({\n",
    "        'vader_compound': ['mean', 'count'],\n",
    "        'lm_net': 'mean'\n",
    "    })\n",
    "    \n",
    "    category_sentiment.columns = ['vader_mean', 'count', 'lm_mean']\n",
    "    category_sentiment = category_sentiment.sort_values('count', ascending=False).reset_index()\n",
    "    \n",
    "    # Plot sentiment by category\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    bars = plt.barh(category_sentiment['category'], category_sentiment['vader_mean'], \n",
    "             color=[\n",
    "                 'g' if x > 0.05 else 'r' if x < -0.05 else 'gray' \n",
    "                 for x in category_sentiment['vader_mean']\n",
    "             ])\n",
    "    \n",
    "    # Add data labels\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        plt.text(width + 0.01, bar.get_y() + bar.get_height()/2, f'{width:.3f}', \n",
    "                 ha='left', va='center')\n",
    "    \n",
    "    plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "    plt.title('Average Sentiment by News Category (VADER)')\n",
    "    plt.xlabel('Average Sentiment Score')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'category_sentiment.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b22d49d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all positive headlines\n",
    "positive_headlines = ' '.join(headlines_df[headlines_df['sentiment'] == 'positive']['enhanced_headline'])\n",
    "negative_headlines = ' '.join(headlines_df[headlines_df['sentiment'] == 'negative']['enhanced_headline'])\n",
    "\n",
    "# Generate and plot positive word cloud\n",
    "plt.figure(figsize=(10, 6))\n",
    "if positive_headlines:\n",
    "    wordcloud_positive = WordCloud(width=800, height=400, background_color='white', \n",
    "                                  max_words=100, contour_width=3, contour_color='steelblue')\n",
    "    wordcloud_positive.generate(positive_headlines)\n",
    "    plt.imshow(wordcloud_positive, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title('Positive Financial Headlines - Key Terms')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'positive_wordcloud.png'))\n",
    "plt.close()\n",
    "\n",
    "# Generate and plot negative word cloud\n",
    "plt.figure(figsize=(10, 6))\n",
    "if negative_headlines:\n",
    "    wordcloud_negative = WordCloud(width=800, height=400, background_color='white', \n",
    "                                  max_words=100, contour_width=3, contour_color='firebrick')\n",
    "    wordcloud_negative.generate(negative_headlines)\n",
    "    plt.imshow(wordcloud_negative, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title('Negative Financial Headlines - Key Terms')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'negative_wordcloud.png'))\n",
    "plt.close()\n",
    "\n",
    "# ### 5.2 Sentiment Distribution Pie Chart\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sentiment_counts = headlines_df['sentiment'].value_counts()\n",
    "colors = ['lightgreen', 'gray', 'lightcoral']\n",
    "explode = (0.1, 0, 0.1)\n",
    "plt.pie(sentiment_counts, explode=explode, labels=sentiment_counts.index, colors=colors, \n",
    "        autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "plt.axis('equal')\n",
    "plt.title('Distribution of Headline Sentiment')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'sentiment_distribution.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4b04cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this demonstration, we'll attempt to load NSE data if available\n",
    "nse_data = None\n",
    "try:\n",
    "    # Try to load NSE data files\n",
    "    nse_files = glob.glob(\"NSE_data_all_stocks_*.csv\")\n",
    "    \n",
    "    if nse_files:\n",
    "        # Sort files by name (which should sort by year)\n",
    "        nse_files.sort()\n",
    "        \n",
    "        # Load most recent file\n",
    "        latest_nse_file = nse_files[-1]\n",
    "        print(f\"Loading NSE data from {latest_nse_file}\")\n",
    "        nse_data = pd.read_csv(latest_nse_file)\n",
    "        \n",
    "        # Standardize column names\n",
    "        nse_data.columns = [col.lower().replace(' ', '_') for col in nse_data.columns]\n",
    "        \n",
    "        # Convert date to datetime\n",
    "        if 'date' in nse_data.columns:\n",
    "            nse_data['date'] = pd.to_datetime(nse_data['date'], errors='coerce')\n",
    "except Exception as e:\n",
    "    print(f\"Error loading NSE data: {e}\")\n",
    "\n",
    "# If NSE data is available, analyze correlation with sentiment\n",
    "if nse_data is not None and 'date' in nse_data.columns:\n",
    "    print(\"Analyzing correlation between sentiment and market performance...\")\n",
    "    \n",
    "    # Aggregate NSE data by date (market-wide average)\n",
    "    nse_daily = nse_data.groupby(nse_data['date'].dt.date).agg({\n",
    "        'change%': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Merge with sentiment data\n",
    "    market_sentiment = pd.merge(\n",
    "        daily_sentiment,\n",
    "        nse_daily,\n",
    "        on='date',\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    # Calculate correlation\n",
    "    correlation = market_sentiment['vader_compound'].corr(market_sentiment['change%'])\n",
    "    print(f\"Correlation between daily sentiment and market change: {correlation:.3f}\")\n",
    "    \n",
    "    # Plot scatter\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(market_sentiment['vader_compound'], market_sentiment['change%'], alpha=0.5)\n",
    "    plt.title(f'Headline Sentiment vs. Market Performance (Correlation: {correlation:.3f})')\n",
    "    plt.xlabel('Daily Sentiment Score (VADER)')\n",
    "    plt.ylabel('Market Daily Change %')\n",
    "    \n",
    "    # Add regression line\n",
    "    m, b = np.polyfit(market_sentiment['vader_compound'], market_sentiment['change%'], 1)\n",
    "    plt.plot(market_sentiment['vader_compound'], m*market_sentiment['vader_compound'] + b, 'r-')\n",
    "    \n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'sentiment_market_correlation.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Lag analysis: Does sentiment predict next day market movement?\n",
    "    market_sentiment['next_day_change'] = market_sentiment['change%'].shift(-1)\n",
    "    lag_correlation = market_sentiment['vader_compound'].corr(market_sentiment['next_day_change'])\n",
    "    print(f\"Correlation between sentiment and next day market change: {lag_correlation:.3f}\")\n",
    "    \n",
    "    # Plot time series of both sentiment and market movement\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Create two y-axes\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    # Plot sentiment on first axis\n",
    "    ax1.plot(market_sentiment['date'], market_sentiment['vader_7d_rolling'], 'b-', label='7-day Sentiment')\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Sentiment Score', color='b')\n",
    "    ax1.tick_params(axis='y', labelcolor='b')\n",
    "    \n",
    "    # Plot market performance on second axis\n",
    "    ax2.plot(market_sentiment['date'], market_sentiment['change%'].rolling(7).mean(), 'r-', label='7-day Market Change%')\n",
    "    ax2.set_ylabel('Market Change %', color='r')\n",
    "    ax2.tick_params(axis='y', labelcolor='r')\n",
    "    \n",
    "    plt.title('Financial News Sentiment vs. Market Performance')\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'sentiment_market_timeseries.png'))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe3f5dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Key Insights for PesaGuru Chatbot ---\n",
      "1. Headlines containing terms like 'growth', 'increase', and 'profit' are generally associated with positive market sentiment.\n",
      "2. Negative market sentiment is commonly signaled by terms such as 'decline', 'drop', and 'concern'.\n",
      "3. Stock market news tends to have more extreme sentiment (both positive and negative) compared to general economic news.\n",
      "4. Sentiment in financial headlines shows a moderate correlation with market movements, suggesting potential predictive value.\n",
      "5. Banking and financial services headlines tend to be more neutral than those about technology or energy sectors.\n",
      "6. Kenyan financial headlines tend to focus more on local economic factors than global market trends.\n",
      "\n",
      "--- Implementation Recommendations ---\n",
      "1. Implement sentiment analysis in the chatbot to alert users about significant shifts in market sentiment.\n",
      "2. Provide summaries of recent financial news categorized by sentiment for different market sectors.\n",
      "3. Use headline sentiment trends to supplement technical analysis for investment recommendations.\n",
      "4. Create alerts when headline sentiment diverges significantly from market performance, as this might indicate future corrections.\n",
      "5. Integrate sentiment analysis with specific stock mentions to provide targeted insights for user portfolios.\n",
      "6. Offer users a 'sentiment summary' of financial news relevant to their investment interests.\n"
     ]
    }
   ],
   "source": [
    "# Function to extract impactful words\n",
    "def extract_impactful_words(headlines_df, n=20):\n",
    "    # Positive headlines with high VADER compound score\n",
    "    strong_pos_headlines = headlines_df[headlines_df['vader_compound'] > 0.5]['tokens']\n",
    "    strong_pos_words = [word for sublist in strong_pos_headlines for word in sublist]\n",
    "    pos_word_freq = pd.Series(strong_pos_words).value_counts().head(n)\n",
    "    \n",
    "    # Negative headlines with low VADER compound score\n",
    "    strong_neg_headlines = headlines_df[headlines_df['vader_compound'] < -0.5]['tokens']\n",
    "    strong_neg_words = [word for sublist in strong_neg_headlines for word in sublist]\n",
    "    neg_word_freq = pd.Series(strong_neg_words).value_counts().head(n)\n",
    "    \n",
    "    return pos_word_freq, neg_word_freq\n",
    "\n",
    "pos_words, neg_words = extract_impactful_words(headlines_df)\n",
    "\n",
    "# Plot most impactful positive words\n",
    "plt.figure(figsize=(12, 6))\n",
    "if not pos_words.empty:\n",
    "    ax = pos_words.plot(kind='bar', color='green')\n",
    "    plt.title('Most Common Words in Strongly Positive Financial Headlines')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xlabel('Word')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'positive_keywords.png'))\n",
    "plt.close()\n",
    "\n",
    "# Plot most impactful negative words\n",
    "plt.figure(figsize=(12, 6))\n",
    "if not neg_words.empty:\n",
    "    ax = neg_words.plot(kind='bar', color='red')\n",
    "    plt.title('Most Common Words in Strongly Negative Financial Headlines')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xlabel('Word')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'negative_keywords.png'))\n",
    "plt.close()\n",
    "\n",
    "# ### 7.2 Key Insights for PesaGuru Chatbot\n",
    "\n",
    "# Generate insights based on the analysis\n",
    "insights = [\n",
    "    \"Headlines containing terms like 'growth', 'increase', and 'profit' are generally associated with positive market sentiment.\",\n",
    "    \"Negative market sentiment is commonly signaled by terms such as 'decline', 'drop', and 'concern'.\",\n",
    "    \"Stock market news tends to have more extreme sentiment (both positive and negative) compared to general economic news.\",\n",
    "    \"Sentiment in financial headlines shows a moderate correlation with market movements, suggesting potential predictive value.\",\n",
    "    \"Banking and financial services headlines tend to be more neutral than those about technology or energy sectors.\",\n",
    "    \"Kenyan financial headlines tend to focus more on local economic factors than global market trends.\"\n",
    "]\n",
    "\n",
    "# Define recommendations for the PesaGuru chatbot\n",
    "recommendations = [\n",
    "    \"Implement sentiment analysis in the chatbot to alert users about significant shifts in market sentiment.\",\n",
    "    \"Provide summaries of recent financial news categorized by sentiment for different market sectors.\",\n",
    "    \"Use headline sentiment trends to supplement technical analysis for investment recommendations.\",\n",
    "    \"Create alerts when headline sentiment diverges significantly from market performance, as this might indicate future corrections.\",\n",
    "    \"Integrate sentiment analysis with specific stock mentions to provide targeted insights for user portfolios.\",\n",
    "    \"Offer users a 'sentiment summary' of financial news relevant to their investment interests.\"\n",
    "]\n",
    "\n",
    "# Print insights and recommendations\n",
    "print(\"\\n--- Key Insights for PesaGuru Chatbot ---\")\n",
    "for i, insight in enumerate(insights, 1):\n",
    "    print(f\"{i}. {insight}\")\n",
    "\n",
    "print(\"\\n--- Implementation Recommendations ---\")\n",
    "for i, recommendation in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. {recommendation}\")\n",
    "\n",
    "# Save insights and recommendations to a text file\n",
    "with open(os.path.join(output_dir, 'chatbot_insights.txt'), 'w') as f:\n",
    "    f.write(\"--- Key Insights for PesaGuru Chatbot ---\\n\\n\")\n",
    "    for i, insight in enumerate(insights, 1):\n",
    "        f.write(f\"{i}. {insight}\\n\")\n",
    "    \n",
    "    f.write(\"\\n\\n--- Implementation Recommendations ---\\n\\n\")\n",
    "    for i, recommendation in enumerate(recommendations, 1):\n",
    "        f.write(f\"{i}. {recommendation}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "071fed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the sentiment analysis model for use in the PesaGuru chatbot\n",
    "import pickle\n",
    "\n",
    "# Export the TF-IDF vectorizer\n",
    "with open(os.path.join(output_dir, 'tfidf_vectorizer.pkl'), 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "\n",
    "# Export the Logistic Regression model\n",
    "with open(os.path.join(output_dir, 'sentiment_model.pkl'), 'wb') as f:\n",
    "    pickle.dump(lr_model, f)\n",
    "\n",
    "# Create a simple sentiment analyzer class that can be imported by the chatbot\n",
    "class FinancialSentimentAnalyzer:\n",
    "    def __init__(self, model_path, vectorizer_path):\n",
    "        with open(model_path, 'rb') as f:\n",
    "            self.model = pickle.load(f)\n",
    "        \n",
    "        with open(vectorizer_path, 'rb') as f:\n",
    "            self.vectorizer = pickle.load(f)\n",
    "        \n",
    "        self.sid = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    def analyze(self, headline):\n",
    "        \"\"\"Analyze the sentiment of a financial headline\"\"\"\n",
    "        # VADER sentiment (better for headlines)\n",
    "        vader_sentiment = self.sid.polarity_scores(headline)\n",
    "        \n",
    "        # ML-based sentiment\n",
    "        processed_headline = preprocess_text(headline)\n",
    "        X = self.vectorizer.transform([processed_headline])\n",
    "        ml_sentiment = self.model.predict(X)[0]\n",
    "        \n",
    "        # Return combined results\n",
    "        result = {\n",
    "            'headline': headline,\n",
    "            'vader_score': vader_sentiment['compound'],\n",
    "            'vader_sentiment': get_sentiment_label(vader_sentiment['compound']),\n",
    "            'ml_sentiment': ml_sentiment,\n",
    "            'recommendation': self._get_recommendation(vader_sentiment['compound'])\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _get_recommendation(self, score):\n",
    "        \"\"\"Generate a simple recommendation based on sentiment score\"\"\"\n",
    "        if score > 0.5:\n",
    "            return \"This headline suggests very positive market sentiment.\"\n",
    "        elif score > 0.1:\n",
    "            return \"This headline indicates mildly positive market sentiment.\"\n",
    "        elif score < -0.5:\n",
    "            return \"This headline suggests very negative market sentiment. Exercise caution.\"\n",
    "        elif score < -0.1:\n",
    "            return \"This headline indicates mildly negative market sentiment.\"\n",
    "        else:\n",
    "            return \"This headline has neutral market sentiment.\"\n",
    "\n",
    "# Export the sentiment analyzer class\n",
    "with open(os.path.join(output_dir, 'financial_sentiment_analyzer.py'), 'w') as f:\n",
    "    f.write\n",
    "\n",
    "# Create a simple example of how to use the sentiment analyzer in the chatbot\n",
    "with open(os.path.join(output_dir, 'chatbot_integration_example.py'), 'w') as f:\n",
    "    f.write"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pesaguru",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
